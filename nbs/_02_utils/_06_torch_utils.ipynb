{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guards\n",
    "\n",
    "> various guards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass, field, KW_ONLY\n",
    "from typing import Optional, List, ClassVar, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iza.types import Tensor, Device, SeriesLike, ndarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "try:\n",
    "    import torch\n",
    "    def ensure_device(device: Device) -> Device:\n",
    "        '''\n",
    "        Given a valid device type attempts to instantiant \n",
    "        a pytorch device object i.e. `device='cpu'` will\n",
    "        return `torch.device('cpu')`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        device : Device\n",
    "            a valid pytorch device type, possible a string.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        device : torch.device        \n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            same error if `torch.device(device)` fails\n",
    "        '''\n",
    "        if device is None:\n",
    "            return device    \n",
    "        try:\n",
    "            return torch.device(device)\n",
    "        except RuntimeError as err:\n",
    "            raise err\n",
    "        return device\n",
    "    \n",
    "    def to_cuda(tensor: Tensor) -> Tensor:\n",
    "        '''\n",
    "        Given a tensor, ensures that it is on cuda.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "        '''\n",
    "        return tensor.cuda()\n",
    "\n",
    "    def to_mps(tensor: Tensor) -> Tensor:\n",
    "        '''\n",
    "        Given a tensor, ensures that it is on mac silicon.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "        '''\n",
    "        return tensor.to(torch.device('mps'))\n",
    "    \n",
    "    \n",
    "    def to_torch(\n",
    "        arr: SeriesLike,\n",
    "        cuda: Optional[bool] = False,\n",
    "        mps: Optional[bool] = False,\n",
    "        device: Optional[Device] = None,\n",
    "        dtype: Optional[Any] = None\n",
    "    ) -> Tensor:\n",
    "        '''\n",
    "        Given data, ensures that it is a pytorch Tensor.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        arr : SeriesLike\n",
    "        \n",
    "        cuda : bool, default=False\n",
    "            whether to return the tensor on cuda\n",
    "            \n",
    "        mps : bool, default=False\n",
    "            whether to return the tensor on mps\n",
    "            \n",
    "        device : Device, optional\n",
    "            whether to return the tensor on given device\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "            the input array as a pytorch tensor\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        - `device` takes priority over `cuda` and `mps`\n",
    "        '''\n",
    "        tensor = torch.as_tensor(arr)\n",
    "        if device is not None:\n",
    "            tensor = tensor.to(device)\n",
    "        elif cuda:\n",
    "            tensor = to_cuda(tensor)\n",
    "        elif mps:\n",
    "            tensor = to_mps(tensor)    \n",
    "        \n",
    "        if dtype is not None:\n",
    "            dtype = coerce_mps_dtype(dtype, tensor.device, assume_on_mps=False)\n",
    "            tensor = tensor.to(dtype)\n",
    "\n",
    "        return tensor\n",
    "    \n",
    "    #| export\n",
    "    def to_np(tensor:Tensor) -> ndarray:\n",
    "        '''\n",
    "        Given a tensor converts it to a numpy array\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        arr : ndarray\n",
    "        '''\n",
    "        assert is_tensor(tensor)\n",
    "        if not hasattr(tensor, 'detach'):\n",
    "            try:\n",
    "                return np.array(tensor)\n",
    "            except Exception as err:\n",
    "                raise err\n",
    "        try:\n",
    "            return tensor.detach().clone().cpu().numpy()\n",
    "        except Exception as err:\n",
    "            raise err\n",
    "    \n",
    "\n",
    "    def is_mps_available() -> bool:\n",
    "        '''\n",
    "        Checks whether or not pytorch has mps availble (version) and was built with mps in mind.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        result : bool\n",
    "        '''\n",
    "        maybe_mps = torch.backends.mps.is_available()\n",
    "        built_mps = torch.backends.mps.is_built()\n",
    "        return maybe_mps and built_mps\n",
    "    \n",
    "    def coerce_mps_dtype(\n",
    "        dtype, \n",
    "        device: Optional[Device] = None, \n",
    "        assume_on_mps: Optional[bool] = True\n",
    "    ):\n",
    "        '''\n",
    "        Makes sure `tensor` is `torch.float32` if `tensor.dtype` is `torch.float64`\n",
    "        if `tensor.device` is `'mps'`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        dtype : any\n",
    "            dtype to check against\n",
    "        \n",
    "        device : Device, default=None\n",
    "            the device of the tensor or model from which the `dtype` comes from. If provided\n",
    "            will be used to detemine whether or not to make `torch.float64`, `torch.float32`\n",
    "            only if the device is actually `'mps'`.\n",
    "\n",
    "        assume_on_mps: bool, default=True\n",
    "            whether or not to assume that the device of choice is `'mps'`. Setting this to\n",
    "            `True` will result in `dtype` of `torch.float64` being converted to `torch.float32`\n",
    "            to try and silently fix mps errors\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dtype : any\n",
    "            the dtype, corrected for mps if needed\n",
    "        '''\n",
    "        could_be_mps = is_mps_available()\n",
    "        \n",
    "        is_float64 = dtype == torch.float64\n",
    "\n",
    "        if device is not None:\n",
    "            is_device_mps = device.type == 'mps'\n",
    "            if is_device_mps:\n",
    "                assume_on_mps = True\n",
    "\n",
    "            elif device.type == 'cuda':\n",
    "                assume_on_mps = False\n",
    "\n",
    "        \n",
    "        # NOTE: float64 not availble on mps, coerce to float32\n",
    "        # NOTE: could_be_mps and assume_on_mps both needed as\n",
    "        #       device might not be provided.\n",
    "        if could_be_mps and assume_on_mps and is_float64:\n",
    "            return torch.float32\n",
    "        \n",
    "        return dtype\n",
    "    \n",
    "    def ensure_mps_dtype(tensor: Tensor) -> Tensor:\n",
    "        '''\n",
    "        Makes sure `tensor` is `torch.float32` if `tensor.dtype` is `torch.float64`\n",
    "        if `tensor.device` is `'mps'`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            pytorch tensor to maybe change dtype of\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "        '''\n",
    "        dtype = tensor.dtype\n",
    "\n",
    "        # NOTE: we don't assume mps as we explicitly pass the device\n",
    "        dtype = coerce_mps_dtype(dtype, tensor.device, assume_on_mps=False)\n",
    "\n",
    "        tensor = tensor.to(dtype)\n",
    "        return tensor\n",
    "\n",
    "    def move_to(\n",
    "        tensor: Tensor, other: Tensor, \n",
    "        dtype: Optional[Any] = None, do_dtype: Optional[bool] = True\n",
    "    ) -> Tensor:\n",
    "        '''\n",
    "        Makes sure `tensor` is on the same device as `other`\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            pytorch tensor to change device of\n",
    "            \n",
    "        other : Tensor\n",
    "            pytorch tensor we want `tensor` to be on\n",
    "            \n",
    "        dtype : optional\n",
    "            the data type to make `tensor`. If `None` will infer it\n",
    "            from `other`\n",
    "            \n",
    "        do_dype: bool, default=True\n",
    "            whether or not to just match the device of `other` or also\n",
    "            the dtype\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "        '''\n",
    "        \n",
    "        if not is_tensor(tensor):\n",
    "            tensor = to_torch(tensor)\n",
    "            \n",
    "        # NOTE: dtype not provided, so we will infer it\n",
    "        if dtype is None:\n",
    "            # NOTE: this little line solves mps float64 issues since \n",
    "            #       infer our tensor types and move them accordingly\n",
    "            other = ensure_mps_dtype(other)\n",
    "            dtype = other.dtype\n",
    "\n",
    "        if do_dtype:\n",
    "            tensor = tensor.to(dtype)\n",
    "\n",
    "        tensor = tensor.to(other.device)\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "except ImportError as err:\n",
    "    identity = lambda x: x\n",
    "    ensure_device = identity\n",
    "    to_cuda = identity\n",
    "    to_mps = identity\n",
    "    to_torch = lambda arr, cuda, mps, device, dtype: arr\n",
    "    to_np = identity\n",
    "    is_mps_available = lambda: False\n",
    "    coerce_mps_dtype = lambda dtype, device, assume_on_mps: dtype\n",
    "    ensure_mps_dtype = identity\n",
    "    move_to = lambda tensor, other, dtype, do_dtype: tensor\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "try:\n",
    "    import torch, pytorch_lightning as pl\n",
    "    def set_seeds(seed: int) -> None:\n",
    "        '''\n",
    "        Calls a bunch of seed functions with `seed`\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int\n",
    "        '''    \n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)    \n",
    "        pl.seed_everything(seed)\n",
    "except ImportError as err:\n",
    "     def set_seeds(seed: int) -> None:\n",
    "         random.seed(seed)\n",
    "         np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
