{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive\n",
    "\n",
    "> archive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, pathlib, itertools\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, KW_ONLY\n",
    "from typing import Optional, List, ClassVar, Any, TypeAlias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iza.types import PathLike, PathType\n",
    "from iza.static import EXT_PY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Viewer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archive Downloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Directory` defined in `_02_utils/_03_directory.ipynb`\n",
    "- `ConsoleType` defined in `_02_utils/_03_directory.ipynb`\n",
    "- `get_console` imported in `_02_utils/_03_directory.ipynb`\n",
    "- `is_rich_available` defined in `_02_utils/_08_archive.ipynb`\n",
    "- `urljoin` defined in `_02_utils/_01_files.ipynb`\n",
    "- `parse_url` imported in `_02_utils/_01_files.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ArchiveDownloader:    \n",
    "    _: KW_ONLY\n",
    "    rootdir: str \n",
    "    archive: str\n",
    "    entries: Union[str, list[str]]\n",
    "    savedir: str\n",
    "    extract: bool = False\n",
    "    cleanup: bool = False\n",
    "    compound_archive: bool = False\n",
    "    archives: Optional[list[str]] = None\n",
    "    console: Optional[ConsoleType] = None\n",
    "    progress: Optional[ProgressType] = None\n",
    "\n",
    "    \n",
    "\n",
    "    def __post_init__(self):        \n",
    "        self.entries = self.entries if isinstance(self.entries, list) else [self.entries]\n",
    "        if is_rich_available():\n",
    "            self.console = get_console()\n",
    "            self.progress = self.get_progress()\n",
    "\n",
    "        self.savedir = Path(self.savedir).expanduser()\n",
    "        make_missing_dirs(self.savedir)\n",
    "\n",
    "    def get_progress(self):\n",
    "        if is_rich_available():\n",
    "            progress = getattr(self, 'progress', None)\n",
    "            if progress is None and Progress is not None:\n",
    "                self.progress = Progress(console=self.console)\n",
    "                return self.progress\n",
    "\n",
    "        elif Progress is None:\n",
    "            return None\n",
    "        \n",
    "        elif Progress is not None:\n",
    "            self.progress = Progress(console=self.console)\n",
    "            return self.progress\n",
    "        \n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def path(self) -> str:\n",
    "        return urljoin(self.rootdir, self.archive)\n",
    "\n",
    "    @property\n",
    "    def urls(self) -> list[str]:\n",
    "        urls = []\n",
    "        if self.compound_archive and self.archives is not None:\n",
    "            for archive, entry in itertools.product(self.archives, self.entries):\n",
    "                urls.append(urljoin(self.rootdir, archive, entry))\n",
    "        else:\n",
    "            urls = [urljoin(self.path, entry) for entry in self.entries]\n",
    "        return urls\n",
    "\n",
    "    def download_missing_files(self) -> None:\n",
    "        total_files = len(self.urls)\n",
    "        if is_rich_available() and self.progress is not None:\n",
    "            with self.progress:\n",
    "                task = self.progress.add_task(\"[cyan]Downloading...\", total=total_files)\n",
    "                for url in self.urls:\n",
    "                    filename = Path(parse_url(url).path).name\n",
    "                    fullpath = self.savedir / filename\n",
    "                    if not fullpath.exists():\n",
    "                        stream_file(url, str(fullpath))\n",
    "                        self.progress.advance(task)\n",
    "        else:            \n",
    "            for url in tqdm(self.urls, desc='Downloading'):       \n",
    "                filename = Path(parse_url(url).path).name\n",
    "                fullpath = self.savedir / filename\n",
    "                if not fullpath.exists():\n",
    "                    stream_file(url, str(fullpath))\n",
    "                # print(\".\", end=\"\")\n",
    "\n",
    "    def extract_files(self) -> None:\n",
    "        files = [self.savedir / entry for entry in self.entries]\n",
    "        if is_rich_available() and self.progress is not None:\n",
    "            with self.progress:\n",
    "                task = self.progress.add_task(\"[cyan]Extracting...\", total=len(files))\n",
    "                for file in files:\n",
    "                    if is_tarball(file):\n",
    "                        decompress_tarball(file)\n",
    "                    elif is_gz(file):\n",
    "                        decompress_gunzip(file, remove=self.cleanup)\n",
    "                    self.progress.advance(task)\n",
    "        else:\n",
    "            for file in tqdm(files, desc='Extracting'):\n",
    "                if is_tarball(file):\n",
    "                    decompress_tarball(file)\n",
    "                elif is_gz(file):\n",
    "                    decompress_gunzip(file, remove=self.cleanup)\n",
    "\n",
    "    def execute(self) -> None:\n",
    "        if is_rich_available():\n",
    "            self.console.print(f\"Processing archive: [bold cyan]{self.archive}[/bold cyan]\")\n",
    "        else:\n",
    "            print(f\"Processing archive: {self.archive}\")\n",
    "        self.download_missing_files()\n",
    "        if self.extract:\n",
    "            self.extract_files()\n",
    "\n",
    "        dir = Directory(self.savedir)\n",
    "        if is_rich_available():\n",
    "            dir.print_rich(self.console)\n",
    "        else:\n",
    "            dir.print()\n",
    "\n",
    "@dataclass\n",
    "class AmazonArchiveDownloader(ArchiveDownloader):\n",
    "    bucket: str\n",
    "    region: str = 'us-east-2'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.rootdir = f\"https://{self.bucket}.s3.{self.region}.amazonaws.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
