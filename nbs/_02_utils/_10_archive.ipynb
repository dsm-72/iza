{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive\n",
    "\n",
    "> archive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, pathlib, itertools\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, KW_ONLY\n",
    "from typing import Optional, List, ClassVar, Any, TypeAlias, Union\n",
    "\n",
    "from ipos.imp import is_mod, is_var_imp, Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iza.types import (\n",
    "    PathLike, PathType,\n",
    "    RichConsole, RichProgress, RichText, RichTree\n",
    ")\n",
    "from iza.static import EXT_PY\n",
    "from iza.imp import RichImp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Viewer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archive Downloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Directory` defined in `_02_utils/_03_directory.ipynb`\n",
    "- `ConsoleType` defined in `_02_utils/_03_directory.ipynb`\n",
    "- `get_console` imported in `_02_utils/_03_directory.ipynb`\n",
    "- `is_rich_available` defined in `_02_utils/_08_archive.ipynb`\n",
    "- `urljoin` defined in `_02_utils/_01_files.ipynb`\n",
    "- `parse_url` imported in `_02_utils/_01_files.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ArchiveDownloader:    \n",
    "    _: KW_ONLY\n",
    "    rootdir: str\n",
    "    archive: str\n",
    "    entries: Union[str, list[str]]\n",
    "    savedir: str\n",
    "    extract: bool = False\n",
    "    cleanup: bool = False\n",
    "    compound_archive: bool = False\n",
    "    archives: Optional[list[str]] = None\n",
    "    console: Optional[RichConsole] = None\n",
    "    progress: Optional[RichProgress] = None\n",
    "\n",
    "    _rich: Module = field(init=False, repr=False, default=None)\n",
    "    has_rich: bool = field(init=False, repr=False, default=None)\n",
    "\n",
    "    \n",
    "\n",
    "    def __post_init__(self):    \n",
    "        r = RichImp()\n",
    "        self._rich = r._module\n",
    "        self.has_rich = is_mod(self._rich)\n",
    "\n",
    "        self.entries = self.entries if isinstance(self.entries, list) else [self.entries]        \n",
    "        self.console = get_console()        \n",
    "        self.progress = self.get_progress()\n",
    "    \n",
    "        self.savedir = Path(self.savedir).expanduser()\n",
    "        make_missing_dirs(self.savedir)\n",
    "\n",
    "    def get_progress(self):\n",
    "        progress = getattr(self, 'progress', None)\n",
    "        if progress is not None:\n",
    "            return progress\n",
    "\n",
    "        if self.has_rich and is_var_imp('Progress'):\n",
    "                self.progress = Progress(console=self.console)\n",
    "                return self.progress\n",
    "\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def path(self) -> str:\n",
    "        return urljoin(self.rootdir, self.archive)\n",
    "\n",
    "    @property\n",
    "    def urls(self) -> list[str]:\n",
    "        urls = []\n",
    "        if self.compound_archive and self.archives is not None:\n",
    "            for archive, entry in itertools.product(self.archives, self.entries):\n",
    "                urls.append(urljoin(self.rootdir, archive, entry))\n",
    "        else:\n",
    "            urls = [urljoin(self.path, entry) for entry in self.entries]\n",
    "        return urls\n",
    "\n",
    "    def download_missing_files(self) -> None:        \n",
    "        total_files = len(self.urls)\n",
    "        if self.has_rich and self.progress:\n",
    "            with self.progress:\n",
    "                task = self.progress.add_task(\"[cyan]Downloading...\", total=total_files)\n",
    "                for url in self.urls:\n",
    "                    filename = Path(parse_url(url).path).name\n",
    "                    fullpath = self.savedir / filename\n",
    "                    if not fullpath.exists():\n",
    "                        stream_file(url, str(fullpath))\n",
    "                        self.progress.advance(task)\n",
    "                    else:\n",
    "                        self.progress.advance(task)\n",
    "        else:            \n",
    "            for url in tqdm(self.urls, desc='Downloading'):       \n",
    "                filename = Path(parse_url(url).path).name\n",
    "                fullpath = self.savedir / filename\n",
    "                if not fullpath.exists():\n",
    "                    stream_file(url, str(fullpath))\n",
    "                \n",
    "\n",
    "    def calc_n_to_extract(self) -> int:\n",
    "        files = [self.savedir / entry for entry in self.entries]\n",
    "        files = get_gz_files_in_dir(self.savedir)\n",
    "        total = 0\n",
    "        for file in files:\n",
    "            if is_tarball(file):\n",
    "                total += 1\n",
    "            elif is_gz(file):\n",
    "                total += 1\n",
    "        return total                \n",
    "\n",
    "    def extract_files(self) -> None:\n",
    "        recurser = RecursiveDecompressor(\n",
    "            dirname=self.savedir, \n",
    "            entries=self.entries,\n",
    "            strategy=undo_gz,\n",
    "            remove=self.cleanup,             \n",
    "            progress=self.progress\n",
    "        )\n",
    "        recurser.decompress()\n",
    "        return\n",
    "        files = [self.savedir / entry for entry in self.entries]\n",
    "        files = get_gz_files_in_dir(self.savedir)\n",
    "        total = self.calc_n_to_extract()\n",
    "        if self.has_rich and self.progress:\n",
    "            with self.progress:\n",
    "                task = self.progress.add_task(\"[cyan]Extracting...\", total=total)\n",
    "                for file in files:\n",
    "                    undo_gz(file, remove=self.cleanup)                    \n",
    "                    self.progress.advance(task)\n",
    "        else:\n",
    "            for file in tqdm(files, desc='Extracting'):\n",
    "                undo_gz(file, remove=self.cleanup)\n",
    "\n",
    "    def execute(self) -> None:\n",
    "        if self.has_rich and self.console:\n",
    "            self.console.print(f\"Processing archive: [bold cyan]{self.archive}[/bold cyan]\")\n",
    "        else:\n",
    "            print(f\"Processing archive: {self.archive}\")\n",
    "\n",
    "        self.download_missing_files()\n",
    "        if self.extract:\n",
    "            self.extract_files()\n",
    "\n",
    "        if self.has_rich and self.console:\n",
    "            dir = RichDirectory(self.savedir, console=self.console)\n",
    "            dir.print_rich()\n",
    "        else:\n",
    "            dir = Directory(self.savedir)\n",
    "            dir.print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: False\n",
    "from iza.static import AMAZON_BUCKET_FLUENTBIO\n",
    "\n",
    "downloader = ArchiveDownloader(\n",
    "    rootdir = AMAZON_BUCKET_FLUENTBIO,\n",
    "    archive = 'public-datasets/pbmc/',\n",
    "    entries = ['combined.html', 'filtered_matrix.tar.gz'],\n",
    "    savedir = '~/Downloads/fluent_bio',  extract=True, cleanup=True\n",
    ")\n",
    "downloader.execute()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: False\n",
    "#| export\n",
    "try:\n",
    "    import typer\n",
    "    app = typer.Typer()\n",
    "\n",
    "    @app.command()\n",
    "    def download(rootdir: str, archive: str, entries: List[str], savedir: str, extract: bool = False, cleanup: bool = False):\n",
    "        downloader = ArchiveDownloader(rootdir, archive, entries, savedir, extract, cleanup)\n",
    "        downloader.execute()\n",
    "\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
