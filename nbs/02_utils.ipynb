{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0bf43ad",
   "metadata": {},
   "source": [
    "# utils\n",
    "> This notebook was generated from the following notebooks:\n",
    "\n",
    "- [_00_utils.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_00_utils.ipynb)\n",
    "- [_01_files.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_01_files.ipynb)\n",
    "- [_02_slice.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_02_slice.ipynb)\n",
    "- [_03_directory.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_03_directory.ipynb)\n",
    "- [_04_filter_matrix_directory.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_04_filter_matrix_directory.ipynb)\n",
    "- [_05_guards.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_05_guards.ipynb)\n",
    "- [_06_torch_utils.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_06_torch_utils.ipynb)\n",
    "- [_09_exp.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_09_exp.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4599ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97decf25",
   "metadata": {},
   "source": [
    "## Utils\n",
    "> This notebook was generated from [_00_utils.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_00_utils.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect, string\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "from typing import List, Any, Optional, Callable, Union, Tuple, Iterable, Set, TypeAlias, Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58d5cab4",
   "metadata": {},
   "source": [
    "### Basic Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9289a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def isiter(val: Any) -> bool:    \n",
    "    return isinstance(val, Iterable)\n",
    "\n",
    "def allinstance(vals:Any, dtype:Union[Type, TypeAlias]=Any) -> bool:\n",
    "    return isiter(vals) and all(isinstance(i, dtype) for i in vals)\n",
    "\n",
    "def allsametype(vals:Any) -> bool:\n",
    "    if not isiter(vals) or len(vals) == 0: return True\n",
    "    dtype = type(vals[0])\n",
    "    return isiter(vals) and all(isinstance(i, dtype) for i in vals)\n",
    "\n",
    "def isin(val:Any, vals:Iterable) -> bool:\n",
    "    return val in vals\n",
    "\n",
    "def arein(vals:Iterable, refs:Iterable) -> bool:                                             \n",
    "    return isiter(vals) and isiter(refs) and all(isin(v, refs) for v in vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834aa7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def str_just_alpha(s:str) -> str:\n",
    "    '''Filters a string for just alpha values'''\n",
    "    return ''.join(list(filter(str.isalpha, s)))\n",
    "\n",
    "def str_just_numeric(s:str) -> str:\n",
    "    '''Filters a string for just numeric values'''\n",
    "    return ''.join(list(filter(str.isnumeric, s)))\n",
    "\n",
    "def strip_punc(s:str) -> str:\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "901bf6d0",
   "metadata": {},
   "source": [
    "### Argument and Key-Word Argument Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_kwargs_for_func(fn: Callable, **kwargs:Optional[dict]):\n",
    "    params = inspect.signature(fn).parameters\n",
    "    return {k:v for k,v in kwargs.items() if k in params}\n",
    "\n",
    "def filter_kwargs_for_class(cls: Callable, **kwargs:Optional[dict]):\n",
    "    params = inspect.signature(cls.__init__).parameters\n",
    "    return {k:v for k,v in kwargs.items() if k in params}\n",
    "\n",
    "def wrangle_kwargs_for_func(\n",
    "    fn: Callable, \n",
    "    defaults: Optional[dict]=None,\n",
    "    **kwargs:Optional[dict]\n",
    ") -> dict:\n",
    "    # copy defaults\n",
    "    params = (defaults or {}).copy()\n",
    "    # update with kwargs of our function\n",
    "    params.update(kwargs or {})\n",
    "    # filter for only the params that other function accepts\n",
    "    params = filter_kwargs_for_func(fn, **params)\n",
    "    return params\n",
    "\n",
    "def wrangle_kwargs_for_class(\n",
    "    cls: Callable, \n",
    "    defaults: Optional[dict]=None,\n",
    "    **kwargs:Optional[dict]\n",
    ") -> dict:\n",
    "    # copy defaults\n",
    "    params = (defaults or {}).copy()\n",
    "    # update with kwargs of our class\n",
    "    params.update(kwargs or {})\n",
    "    # filter for only the params that other class accepts\n",
    "    params = filter_kwargs_for_class(cls, **params)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fffdc7a",
   "metadata": {},
   "source": [
    "## Files\n",
    "> This notebook was generated from [_01_files.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_01_files.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, sys, pwd, atexit, tempfile, inspect\n",
    "import requests, tarfile, gzip, shutil\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Optional, List, Union, Iterable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iza.static import (\n",
    "    EXT_GZ, EXT_TAR, EXT_TAR_GZ,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57a8fc36",
   "metadata": {},
   "source": [
    "### User Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_user() -> str:\n",
    "    user = pwd.getpwuid(os.getuid())[0]\n",
    "    return user\n",
    "\n",
    "def collapse_user(path: str) -> str:\n",
    "    _, rest = path.split(get_user())    \n",
    "    return '~' + rest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "712623c3",
   "metadata": {},
   "source": [
    "### Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_ext(filename:str, extension:str) -> bool:\n",
    "    has_extension = extension in filename \n",
    "    splits = filename.split(extension)\n",
    "    is_end_of_str = len(splits) >= 2 and splits[-1] == ''\n",
    "    is_end_of_str = filename.endswith(extension)\n",
    "    return has_extension and is_end_of_str\n",
    "\n",
    "def drop_ext(filename:str, extension:Optional[str]=None) -> str:\n",
    "    file = os.path.basename(filename)\n",
    "    if extension is None:\n",
    "        file, *_ = file.split('.')\n",
    "    else:\n",
    "        file = filename.replace(extension, '')\n",
    "    return os.path.join(os.path.dirname(filename), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_tar(filename:str) -> bool:\n",
    "    return check_ext(filename, EXT_TAR)\n",
    "\n",
    "def is_gz(filename:str) -> bool:\n",
    "    return check_ext(filename, EXT_GZ)\n",
    "\n",
    "def is_targz(filename:str) -> bool:\n",
    "    return check_ext(filename, EXT_TAR_GZ)\n",
    "\n",
    "def is_tarball(filename:str) -> bool:\n",
    "    return is_tar(filename) or is_targz(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_for_gz_files(files:List[str]) -> List[str]:\n",
    "    return list(filter(lambda f: is_gz(f), files))\n",
    "\n",
    "def get_gz_files_in_dir(dirname:str) -> List[str]:\n",
    "    all_files = []\n",
    "\n",
    "    for (root, dirs, files) in os.walk(dirname):   \n",
    "        fullpaths = [os.path.join(root, file) for file in files]\n",
    "        all_files.extend(fullpaths)\n",
    "    \n",
    "    gz_files = filter_for_gz_files(all_files)\n",
    "    return gz_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d66ea32e",
   "metadata": {},
   "source": [
    "### Decompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cca68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def decompress_tarball(filename:str) -> Tuple[str, Optional[EOFError]]:\n",
    "    '''\n",
    "    Returns\n",
    "    -------\n",
    "        dirname : str\n",
    "            The name of the archive e.g. `~/Downloads/fluentbio.tar.gz` would\n",
    "            yield `~/Downloads/fluentbio`\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    FluentBio has a weird gzip so it complains when it is \n",
    "        actually fine\n",
    "    '''\n",
    "    error = None\n",
    "    decompress_dir = os.path.dirname(filename)\n",
    "    dirname = drop_ext(filename, EXT_TAR_GZ)\n",
    "    try:\n",
    "        with tarfile.open(filename) as tarball:\n",
    "            tarball.extractall(decompress_dir)\n",
    "            tarball.close()\n",
    "\n",
    "    except EOFError as error:\n",
    "        pass\n",
    "\n",
    "    return dirname, error\n",
    "\n",
    "\n",
    "def decompress_gunzip(filename:str, remove:bool=False) -> Tuple[str, Optional[EOFError]]:\n",
    "    '''\n",
    "    Returns\n",
    "    -------\n",
    "        file : str\n",
    "            The name of the decompressed file e.g. `~/Downloads/fluentbio.tsv.gz` would\n",
    "            yield `~/Downloads/fluentbio.tsv`\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    FluentBio has a weird gzip so it complains when it is \n",
    "        actually fine\n",
    "    '''\n",
    "    error = None\n",
    "    decompressed_file = drop_ext(filename, EXT_GZ)\n",
    "    try:             \n",
    "        with gzip.open(filename, 'rb') as gunzipped:\n",
    "            with open(decompressed_file, 'wb') as unzipped:\n",
    "                shutil.copyfileobj(gunzipped, unzipped)     \n",
    "                   \n",
    "    except EOFError as error:\n",
    "        pass\n",
    "\n",
    "    if os.path.isfile(decompressed_file) and remove:\n",
    "        os.remove(filename)\n",
    "\n",
    "    return decompressed_file, error\n",
    "\n",
    "def undo_gz(filename: str) -> str:\n",
    "    if is_gz(filename):\n",
    "        filename, _ = decompress_gunzip(filename, remove=True)\n",
    "    elif is_tarball(filename):\n",
    "        filename, _ = decompress_tarball(filename)\n",
    "    return filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4ab7021",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_missing_dirs(dirs:List[str]):\n",
    "    if isinstance(dirs, str):\n",
    "        dirs = [dirs]\n",
    "        \n",
    "    for d in dirs:\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "            \n",
    "def dir_dirs(dirname:str) -> List[str]:\n",
    "    entries = os.listdir(dirname)\n",
    "    is_subdir = lambda e : os.path.isdir(os.path.join(dirname, e))\n",
    "    return list(filter(is_subdir, entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba668032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def decompress_directory_of_gunzipped_files(\n",
    "    dirname:str, desc:Optional[str]=None, remove:Optional[bool]=False\n",
    ") -> None:\n",
    "    if desc is None:\n",
    "        desc = dirname.split('/')[-1]\n",
    "\n",
    "    gz_files = get_gz_files_in_dir(dirname)\n",
    "    for filename in tqdm(gz_files, desc=desc):\n",
    "        decomp_filename, error = decompress_gunzip(filename, remove)   \n",
    "\n",
    "\n",
    "def decompress_tarball_of_gunzipped_files(\n",
    "    filename:str, desc:Optional[str]=None, remove:Optional[bool]=False\n",
    ") -> None:\n",
    "    # NOTE: initial decompress of .tar.gz\n",
    "    dirname, error = decompress_tarball(filename)\n",
    "\n",
    "    if desc is None:\n",
    "        desc = dirname.split('/')[-1]\n",
    "\n",
    "    # NOTE: decompress all internal .gz files\n",
    "    decompress_directory_of_gunzipped_files(dirname, desc, remove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f382a1f",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8042c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def stream_file(uri:str, filename:Optional[str]=None, desc:Optional[str]=None) -> None:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    uri : str\n",
    "        The URI to download\n",
    "\n",
    "    filename : str, optional\n",
    "        The fullpath name of the file to download. Defaults to \n",
    "        `~/Downloads/os.path.basename(uri)`.\n",
    "\n",
    "    desc : str, optional\n",
    "        The description of the `tqdm` progress bar. Defaults to \n",
    "        `os.path.basename(uri)`.\n",
    "    '''\n",
    "    if filename is None:\n",
    "        download_dir = os.path.expanduser(f'~/Downloads')        \n",
    "        filename = os.path.join(download_dir, os.path.basename(uri))\n",
    "\n",
    "    basename = os.path.basename(filename)\n",
    "    if desc is None:\n",
    "        desc = basename\n",
    "\n",
    "    response = requests.get(uri, stream=True)\n",
    "    total = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with tqdm.wrapattr(\n",
    "        open(filename, 'wb'), 'write', \n",
    "        miniters=1, desc=desc, total=total\n",
    "    ) as fout:\n",
    "        for chunk in response.iter_content(chunk_size=4096):\n",
    "            fout.write(chunk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a21d6ee2",
   "metadata": {},
   "source": [
    "### Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_and_decompress_tarball_of_gunzipped_files(\n",
    "    uri:str, download_dir:str=None, desc:Optional[str]=None, remove:Optional[bool]=False\n",
    "):\n",
    "    filename = os.path.basename(uri)\n",
    "    fullpath = os.path.join(download_dir, filename)\n",
    "\n",
    "    if desc is None:\n",
    "        description = f'Downloading {filename}'\n",
    "\n",
    "\n",
    "    # NOTE: Amazon --> filtered_matrix.tar.gz\n",
    "    stream_file(uri, description)\n",
    "\n",
    "    if desc is None:\n",
    "        description = f'Decompressing {filename}'\n",
    "    # NOTE: filtered_matrix.tar.gz --> filtered_matrix/**/file.tsv\n",
    "    decompress_tarball_of_gunzipped_files(fullpath, desc, remove)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72b48bbe",
   "metadata": {},
   "source": [
    "### Temporary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_temp_file(**kwargs: Any) -> tempfile.NamedTemporaryFile:\n",
    "    temp = tempfile.NamedTemporaryFile(**kwargs)\n",
    "    @atexit.register\n",
    "    def delete_temp() -> None:\n",
    "        temp.close()\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f37f69b",
   "metadata": {},
   "source": [
    "## Slice\n",
    "> This notebook was generated from [_02_slice.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_02_slice.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53664c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "from typing import List, Union, Tuple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2c0326a",
   "metadata": {},
   "source": [
    "### Slice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa3766e0",
   "metadata": {},
   "source": [
    "Helps convert `slices` to its numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Slice:\n",
    "    \"\"\"A class for representing a slice and providing conversion to other formats.\"\"\"\n",
    "    slc: slice = field(default_factory=slice)\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        try:\n",
    "            return self._start\n",
    "        except AttributeError:\n",
    "            self._start = self.slc.start\n",
    "        return self._start\n",
    "    \n",
    "    @start.setter\n",
    "    def start(self, value):\n",
    "        \"\"\"Sets the start index.\"\"\"\n",
    "        if value < 0:\n",
    "            raise ValueError(\"Slice indices must be non-negative.\")\n",
    "        self._start = value\n",
    "\n",
    "    @property\n",
    "    def stop(self):\n",
    "        try:\n",
    "            return self._stop\n",
    "        except AttributeError:\n",
    "            self._stop = self.slc.stop\n",
    "        return self._stop\n",
    "    \n",
    "    @stop.setter\n",
    "    def stop(self, value):\n",
    "        \"\"\"Sets the stop index.\"\"\"\n",
    "        if value < 0:\n",
    "            raise ValueError(\"Slice indices must be non-negative.\")\n",
    "        self._stop = value\n",
    "    \n",
    "    @property\n",
    "    def step(self):\n",
    "        \"\"\"Gets the step index.\"\"\"\n",
    "        try:\n",
    "            return self._step\n",
    "        except AttributeError:\n",
    "            self._step = self.slc.step\n",
    "        return self._step\n",
    "    \n",
    "    @step.setter\n",
    "    def step(self, value):\n",
    "        \"\"\"Sets the step index.\"\"\"\n",
    "        if value < 0:\n",
    "            raise ValueError(\"Slice step must be non-negative.\")\n",
    "        self._step = value\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.start is None:\n",
    "            self.start = 0\n",
    "\n",
    "        if self.stop is None:\n",
    "            self.stop = min(0, self.start, max(1, self.start))\n",
    "\n",
    "        if self.step is None:\n",
    "            self.step = 1\n",
    "\n",
    "    def totuple(self) -> Tuple[Union[int, float, None], Union[int, float, None], Union[int, float, None]]:\n",
    "        \"\"\"Converts the slice to a tuple.\"\"\"\n",
    "        return (self.start, self.stop, self.step)\n",
    "    \n",
    "    def toslice(self) -> slice:\n",
    "        \"\"\"Converts the updated slice.\"\"\"\n",
    "        return slice(self.start, self.stop, self.step)\n",
    "    \n",
    "    def tolist(self) -> List[Union[int, float]]:\n",
    "        \"\"\"Converts the slice to a list.\"\"\"\n",
    "        return list(range(self.start, self.stop, self.step))\n",
    "    \n",
    "    def todict(self) -> List[Union[int, float]]:\n",
    "        \"\"\"Converts the slice to a dict.\"\"\"\n",
    "        return dict(zip('start stop step'.split(), self.totuple()))\n",
    "        \n",
    "\n",
    "    def astype(self, dtype:str):\n",
    "        \"\"\"Converts the slice to a specified format.\"\"\"\n",
    "        if dtype in {'list', list}:\n",
    "            return self.tolist()\n",
    "        elif dtype in {'numpy', np.ndarray}:\n",
    "            return np.array(self.tolist())\n",
    "        elif dtype in {'pandas', pd.Series}:\n",
    "            return pd.Series(self.tolist())\n",
    "        elif dtype in {'tuple', tuple}:\n",
    "            return self.totuple()\n",
    "        elif dtype in {'dict', dict}:\n",
    "            return self.todict()\n",
    "        elif dtype in {'slice', slice}:\n",
    "            return self.toslice()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb480bb",
   "metadata": {},
   "source": [
    "## Director\n",
    "> This notebook was generated from [_03_directory.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_03_directory.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, KW_ONLY\n",
    "from typing import Optional, List, ClassVar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d999ec75",
   "metadata": {},
   "source": [
    "### Directory Viewer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "911a8e48",
   "metadata": {},
   "source": [
    "#### Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@dataclass\n",
    "class Directory:\n",
    "    dirname: str\n",
    "\n",
    "    _: KW_ONLY\n",
    "    _SPACE : ClassVar[str] = '    '\n",
    "    _BRANCH: ClassVar[str] = '│   '    \n",
    "    _TEE   : ClassVar[str] = '├── '\n",
    "    _LAST  : ClassVar[str] = '└── '\n",
    "\n",
    "        \n",
    "    def make_tree(self, dirname:Path, prefix:str=''):\n",
    "        '''\n",
    "        A recursive generator, given a directory Path object\n",
    "        will yield a visual tree structure line by line\n",
    "        with each line prefixed by the same characters\n",
    "        Notes\n",
    "        -----\n",
    "        Adapted from https://stackoverflow.com/a/59109706/5623899\n",
    "        '''\n",
    "\n",
    "        contents = list(dirname.iterdir())\n",
    "        # NOTE: contents each get pointers that are ├── with a final └── :\n",
    "        pointers = [self._TEE] * (len(contents) - 1) + [self._LAST]\n",
    "        for pointer, path in zip(pointers, contents):\n",
    "            yield f'{prefix}{pointer}{path.name}'\n",
    "\n",
    "            # NOTE: extend the prefix and recurse:\n",
    "            if path.is_dir(): \n",
    "                # NOTE: space because last, └── , above so no more |\n",
    "                extension = self._BRANCH if pointer == self._TEE else self._SPACE \n",
    "                \n",
    "                yield from self.make_tree(path, prefix=f'{prefix}{extension}')\n",
    "\n",
    "    def get_tree_lines(self, dirname:Optional[str]=None) -> List[str]:\n",
    "        dirname = self.prepare_dirname(dirname)\n",
    "        tree = self.make_tree(dirname)\n",
    "        lines = [line for line in tree]\n",
    "        return lines\n",
    "\n",
    "    def make_tree_str(self, dirname:Optional[str]=None) -> str:\n",
    "        dirname = self.prepare_dirname(dirname)\n",
    "        lines = self.get_tree_lines(dirname)\n",
    "        tree_str = '\\n'.join([str(dirname), *lines])\n",
    "        return tree_str\n",
    "        \n",
    "    def prepare_dirname(self, dirname:Optional[str]=None) -> Path:\n",
    "        if dirname is None:\n",
    "            dirname = self.dirname\n",
    "\n",
    "        dirname = os.path.expanduser(dirname) \n",
    "        dirname = os.path.abspath(dirname) \n",
    "\n",
    "        if not isinstance(dirname, Path):\n",
    "            dirname = Path(dirname)\n",
    "\n",
    "        return dirname\n",
    "\n",
    "    def print(self, dirname:Optional[str]=None) -> None:\n",
    "        dirname = self.prepare_dirname(dirname)\n",
    "        tree_str = self.make_tree_str(dirname)\n",
    "        print(tree_str)\n",
    "        return\n",
    "\n",
    "    def __repr__(self):\n",
    "        dirname = self.dirname\n",
    "        dirname = self.prepare_dirname(dirname)\n",
    "        tree_str = self.make_tree_str(dirname)        \n",
    "        return tree_str        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e3ff17",
   "metadata": {},
   "source": [
    "## Filter matrix director\n",
    "> This notebook was generated from [_04_filter_matrix_directory.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_04_filter_matrix_directory.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, KW_ONLY\n",
    "from typing import Optional, List, ClassVar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d12ea61e",
   "metadata": {},
   "source": [
    "### Filter Matrix Directory Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33415a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iza.static import (\n",
    "    ADATA, MATRIX, BARCODES, FEATURES, EXT_H5, EXT_MTX, EXT_TSV,\n",
    "    GENE_SYMBOL, ENSEMBL_ID\n",
    ")\n",
    "from iza.types import (\n",
    "    AnnData\n",
    ")\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "try: \n",
    "    import scanpy as sc, scprep\n",
    "\n",
    "    # NOTE: Directory defined in _02_utils/_02_directory.ipynb\n",
    "    @dataclass\n",
    "    class FilterMatrixDirectory(Directory):\n",
    "        _: KW_ONLY\n",
    "        ADATA_FILE: ClassVar[str] = f'{ADATA}{EXT_H5}'\n",
    "        MATRIX_FILE: ClassVar[str] = f'{MATRIX}{EXT_MTX}'\n",
    "        BARCODES_FILE: ClassVar[str] = f'{BARCODES}{EXT_TSV}'\n",
    "        FEATURES_FILE: ClassVar[str] = f'{FEATURES}{EXT_TSV}'\n",
    "        \n",
    "\n",
    "        def __post_init__(self):    \n",
    "            try:\n",
    "                if not self.has_adata:\n",
    "                    self.make_adata()\n",
    "            except Exception as err:\n",
    "                raise err\n",
    "\n",
    "        def __repr__(self):\n",
    "            base = os.path.basename(self.dirname)\n",
    "            srep = f'FilteredMatrix(valid: {self.is_valid}, adata: {self.has_adata})'        \n",
    "            srep += '\\n'\n",
    "            srep += super(FilterMatrixDirectory, self).__repr__()\n",
    "            return srep\n",
    "                    \n",
    "        @property\n",
    "        def adata_filename(self) -> str:\n",
    "            return os.path.join(self.dirname, self.ADATA_FILE)\n",
    "\n",
    "        @property\n",
    "        def matrix_filename(self) -> str:\n",
    "            return os.path.join(self.dirname, self.MATRIX_FILE)\n",
    "        \n",
    "        @property\n",
    "        def barcodes_filename(self) -> str:\n",
    "            return os.path.join(self.dirname, self.BARCODES_FILE)\n",
    "        \n",
    "        @property\n",
    "        def features_filename(self) -> str:\n",
    "            return os.path.join(self.dirname, self.FEATURES_FILE)\n",
    "\n",
    "        @property\n",
    "        def has_adata(self) -> bool:\n",
    "            return os.path.isfile(self.adata_filename)\n",
    "\n",
    "        @property\n",
    "        def has_matrix(self) -> bool:\n",
    "            return os.path.isfile(self.matrix_filename)\n",
    "\n",
    "        @property\n",
    "        def has_barcodes(self) -> bool:\n",
    "            return os.path.isfile(self.barcodes_filename)\n",
    "\n",
    "        @property\n",
    "        def has_features(self) -> bool:\n",
    "            return os.path.isfile(self.features_filename)\n",
    "\n",
    "        @property\n",
    "        def is_valid(self) -> bool:\n",
    "            return all([self.has_matrix, self.has_barcodes, self.has_features])\n",
    "\n",
    "        def make_adata(self) -> AnnData:\n",
    "            if self.has_adata:\n",
    "                return\n",
    "\n",
    "            steps = (FEATURES, BARCODES, MATRIX, 'combine', ADATA)\n",
    "            \n",
    "            desc = os.path.basename(self.dirname)\n",
    "\n",
    "            steps = tqdm(steps, desc=desc, leave=True)        \n",
    "            for step in steps:\n",
    "                steps.set_postfix(stage=step)\n",
    "                match step:\n",
    "                    case 'features':\n",
    "                        features = pd.read_csv(self.features_filename, sep='\\t', header=None)\n",
    "                        features.columns = [ENSEMBL_ID, GENE_SYMBOL, 'feature_type']\n",
    "                        features.index = pd.Series(features.ensembl_id.copy().values)\n",
    "\n",
    "                    case 'barcodes':\n",
    "                        barcodes = pd.read_csv(self.barcodes_filename, sep='\\t', header=None)\n",
    "                        barcodes.columns = [BARCODES]\n",
    "                        barcodes.index = pd.Series(barcodes.barcodes.copy().values)\n",
    "\n",
    "                    case 'matrix':\n",
    "                        matrix = scprep.io.load_mtx(self.matrix_filename, sparse=True).T\n",
    "\n",
    "                    case 'combine':\n",
    "                        data = pd.DataFrame.sparse.from_spmatrix(\n",
    "                            matrix, columns=features.index, index = barcodes.index\n",
    "                        )\n",
    "                        del matrix\n",
    "\n",
    "                    case 'adata':\n",
    "                        adata = sc.AnnData(X=data.values, obs=barcodes, var=features, dtype='float32')\n",
    "                        adata.write(self.adata_filename)\n",
    "\n",
    "                    case _:\n",
    "                        pass\n",
    "\n",
    "            return adata\n",
    "\n",
    "        def get_adata(self) -> AnnData:\n",
    "            adata = sc.read_h5ad(self.adata_filename)\n",
    "            return adata\n",
    "\n",
    "except ImportError as err:\n",
    "    @dataclass\n",
    "    class FilterMatrixDirectory(Directory):\n",
    "        _: KW_ONLY\n",
    "        ADATA_FILE: ClassVar[str] = f'{ADATA}{EXT_H5}'\n",
    "        MATRIX_FILE: ClassVar[str] = f'{MATRIX}{EXT_MTX}'\n",
    "        BARCODES_FILE: ClassVar[str] = f'{BARCODES}{EXT_TSV}'\n",
    "        FEATURES_FILE: ClassVar[str] = f'{FEATURES}{EXT_TSV}'\n",
    "        \n",
    "\n",
    "        def __post_init__(self):    \n",
    "            raise ImportError('FilterMatrixDirectory requires scprep and scanpy to be installed')\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20881319",
   "metadata": {},
   "source": [
    "## Guards\n",
    "> This notebook was generated from [_05_guards.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_05_guards.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709531e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import numpy as np, pandas as pd\n",
    "from typing import Optional, List, ClassVar, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f67dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iza.types import Tensor, Device, SeriesLike, ndarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "698a0278",
   "metadata": {},
   "source": [
    "### Guards"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7ba3df7",
   "metadata": {},
   "source": [
    "#### Numpy and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30232017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_matrix(arr: SeriesLike) -> bool:\n",
    "    '''\n",
    "    Checks whether or not `arr` is a np.matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    arr : SeriesLike\n",
    "        object to check whether or not it is a np.matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool\n",
    "    '''\n",
    "    return isinstance(arr, np.matrix)\n",
    "\n",
    "def undo_npmatrix(arr: SeriesLike) -> SeriesLike:  \n",
    "    '''\n",
    "    Given a tensor converts it to a numpy array\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    tensor : Tensor\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    arr : ndarray\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - several graphtool functions use dependencies which rely on\n",
    "        the deprecated numpy class `np.matrix`.\n",
    "        \n",
    "    - these functions appear to be related to scipy sparse linalg\n",
    "        methods.\n",
    "    '''\n",
    "    if is_matrix(arr):\n",
    "        return np.array(arr)\n",
    "    return arr\n",
    "\n",
    "def is_series(arr: SeriesLike) -> bool:\n",
    "    '''\n",
    "    Checks whether or not `arr` is a pd.Series\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    arr : SeriesLike\n",
    "        object to check whether or not it is a pd.Series.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool\n",
    "    '''\n",
    "    return isinstance(arr, pd.Series)\n",
    "\n",
    "def is_series_like(series_q: SeriesLike) -> bool:\n",
    "    '''\n",
    "    Checks whether or not `series_q` is SeriesLike\n",
    "    i.e. something that is probably data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    series_q : SeriesLike\n",
    "        object to check whether or not it is a SeriesLike.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool\n",
    "    '''\n",
    "    return isinstance(series_q, SeriesLike)\n",
    "\n",
    "def is_np(arr_q: SeriesLike) -> bool:\n",
    "    '''\n",
    "    Checks whether or not `arr_q` is a ndarray\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    arr_q : SeriesLike\n",
    "        object to check whether or not it is a SeriesLike.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool\n",
    "    '''\n",
    "    return isinstance(arr_q, ndarray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_device(device_q: Device) -> bool:\n",
    "    '''\n",
    "    Checks whether or not `device_q` is a valid\n",
    "    pytorch device type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    device_q : Device\n",
    "        object to check whether or not it is a pytorch device.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool        \n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - There is an execption. `NoneType` is a valid\n",
    "        pytorch device. Here we return `False` instead.\n",
    "    '''\n",
    "    if device_q is None:\n",
    "        return False\n",
    "    return isinstance(device_q, Device)\n",
    "\n",
    "def is_cpu(tensor: Tensor) -> bool:\n",
    "    '''\n",
    "    Checks whether or not `tensor` is on cpu\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    tensor : Tensor\n",
    "        object to check whether or not it is on cpu.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool\n",
    "    '''\n",
    "    # assert is_tensor(tensor)\n",
    "    if not hasattr(tensor, 'device'):\n",
    "        return True\n",
    "    return tensor.device.type == 'cpu'\n",
    "\n",
    "def is_mps(tensor: Tensor) -> bool:\n",
    "    '''\n",
    "    Checks whether or not `tensor` is on cpu\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    tensor : Tensor\n",
    "        object to check whether or not it is on cpu.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool\n",
    "    '''\n",
    "    # assert is_tensor(tensor)\n",
    "    if not hasattr(tensor, 'device'):\n",
    "        return False\n",
    "    return tensor.device.type == 'mps'\n",
    "\n",
    "def is_tensor(tensor_q: SeriesLike) -> bool:\n",
    "    '''\n",
    "    Checks whether or not `tensor_q` is a pytorch tensor\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    tensor_q : Tensor\n",
    "        object to check whether or not it is a pytorch tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool\n",
    "    '''\n",
    "    return isinstance(tensor_q, Tensor)\n",
    "\n",
    "\n",
    "def is_torch(tensor_q: SeriesLike) -> bool:\n",
    "    '''\n",
    "    Alias for `is_tensor`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    tensor_q : Tensor\n",
    "        object to check whether or not it is a pytorch tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : bool\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    is_tensor\n",
    "    '''\n",
    "    return is_tensor(tensor_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce9b2be",
   "metadata": {},
   "source": [
    "## Torch utils\n",
    "> This notebook was generated from [_06_torch_utils.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_06_torch_utils.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass, field, KW_ONLY\n",
    "from typing import Optional, List, ClassVar, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iza.types import Tensor, Device, SeriesLike, ndarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3658eb56",
   "metadata": {},
   "source": [
    "### Torch Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b9d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "try:\n",
    "    import torch\n",
    "    def ensure_device(device: Device) -> Device:\n",
    "        '''\n",
    "        Given a valid device type attempts to instantiant \n",
    "        a pytorch device object i.e. `device='cpu'` will\n",
    "        return `torch.device('cpu')`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        device : Device\n",
    "            a valid pytorch device type, possible a string.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        device : torch.device        \n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            same error if `torch.device(device)` fails\n",
    "        '''\n",
    "        if device is None:\n",
    "            return device    \n",
    "        try:\n",
    "            return torch.device(device)\n",
    "        except RuntimeError as err:\n",
    "            raise err\n",
    "        return device\n",
    "    \n",
    "    def to_cuda(tensor: Tensor) -> Tensor:\n",
    "        '''\n",
    "        Given a tensor, ensures that it is on cuda.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "        '''\n",
    "        return tensor.cuda()\n",
    "\n",
    "    def to_mps(tensor: Tensor) -> Tensor:\n",
    "        '''\n",
    "        Given a tensor, ensures that it is on mac silicon.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "        '''\n",
    "        return tensor.to(torch.device('mps'))\n",
    "    \n",
    "    \n",
    "    def to_torch(\n",
    "        arr: SeriesLike,\n",
    "        cuda: Optional[bool] = False,\n",
    "        mps: Optional[bool] = False,\n",
    "        device: Optional[Device] = None,\n",
    "        dtype: Optional[Any] = None\n",
    "    ) -> Tensor:\n",
    "        '''\n",
    "        Given data, ensures that it is a pytorch Tensor.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        arr : SeriesLike\n",
    "        \n",
    "        cuda : bool, default=False\n",
    "            whether to return the tensor on cuda\n",
    "            \n",
    "        mps : bool, default=False\n",
    "            whether to return the tensor on mps\n",
    "            \n",
    "        device : Device, optional\n",
    "            whether to return the tensor on given device\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "            the input array as a pytorch tensor\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        - `device` takes priority over `cuda` and `mps`\n",
    "        '''\n",
    "        tensor = torch.as_tensor(arr)\n",
    "        if device is not None:\n",
    "            tensor = tensor.to(device)\n",
    "        elif cuda:\n",
    "            tensor = to_cuda(tensor)\n",
    "        elif mps:\n",
    "            tensor = to_mps(tensor)    \n",
    "        \n",
    "        if dtype is not None:\n",
    "            dtype = coerce_mps_dtype(dtype, tensor.device, assume_on_mps=False)\n",
    "            tensor = tensor.to(dtype)\n",
    "\n",
    "        return tensor\n",
    "    \n",
    "    #| export\n",
    "    def to_np(tensor:Tensor) -> ndarray:\n",
    "        '''\n",
    "        Given a tensor converts it to a numpy array\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        arr : ndarray\n",
    "        '''\n",
    "        assert is_tensor(tensor)\n",
    "        if not hasattr(tensor, 'detach'):\n",
    "            try:\n",
    "                return np.array(tensor)\n",
    "            except Exception as err:\n",
    "                raise err\n",
    "        try:\n",
    "            return tensor.detach().clone().cpu().numpy()\n",
    "        except Exception as err:\n",
    "            raise err\n",
    "    \n",
    "\n",
    "    def is_mps_available() -> bool:\n",
    "        '''\n",
    "        Checks whether or not pytorch has mps availble (version) and was built with mps in mind.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        result : bool\n",
    "        '''\n",
    "        maybe_mps = torch.backends.mps.is_available()\n",
    "        built_mps = torch.backends.mps.is_built()\n",
    "        return maybe_mps and built_mps\n",
    "    \n",
    "    def coerce_mps_dtype(\n",
    "        dtype, \n",
    "        device: Optional[Device] = None, \n",
    "        assume_on_mps: Optional[bool] = True\n",
    "    ):\n",
    "        '''\n",
    "        Makes sure `tensor` is `torch.float32` if `tensor.dtype` is `torch.float64`\n",
    "        if `tensor.device` is `'mps'`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        dtype : any\n",
    "            dtype to check against\n",
    "        \n",
    "        device : Device, default=None\n",
    "            the device of the tensor or model from which the `dtype` comes from. If provided\n",
    "            will be used to detemine whether or not to make `torch.float64`, `torch.float32`\n",
    "            only if the device is actually `'mps'`.\n",
    "\n",
    "        assume_on_mps: bool, default=True\n",
    "            whether or not to assume that the device of choice is `'mps'`. Setting this to\n",
    "            `True` will result in `dtype` of `torch.float64` being converted to `torch.float32`\n",
    "            to try and silently fix mps errors\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dtype : any\n",
    "            the dtype, corrected for mps if needed\n",
    "        '''\n",
    "        could_be_mps = is_mps_available()\n",
    "        \n",
    "        is_float64 = dtype == torch.float64\n",
    "\n",
    "        if device is not None:\n",
    "            is_device_mps = device.type == 'mps'\n",
    "            if is_device_mps:\n",
    "                assume_on_mps = True\n",
    "\n",
    "            elif device.type == 'cuda':\n",
    "                assume_on_mps = False\n",
    "\n",
    "        \n",
    "        # NOTE: float64 not availble on mps, coerce to float32\n",
    "        # NOTE: could_be_mps and assume_on_mps both needed as\n",
    "        #       device might not be provided.\n",
    "        if could_be_mps and assume_on_mps and is_float64:\n",
    "            return torch.float32\n",
    "        \n",
    "        return dtype\n",
    "    \n",
    "    def ensure_mps_dtype(tensor: Tensor) -> Tensor:\n",
    "        '''\n",
    "        Makes sure `tensor` is `torch.float32` if `tensor.dtype` is `torch.float64`\n",
    "        if `tensor.device` is `'mps'`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            pytorch tensor to maybe change dtype of\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "        '''\n",
    "        dtype = tensor.dtype\n",
    "\n",
    "        # NOTE: we don't assume mps as we explicitly pass the device\n",
    "        dtype = coerce_mps_dtype(dtype, tensor.device, assume_on_mps=False)\n",
    "\n",
    "        tensor = tensor.to(dtype)\n",
    "        return tensor\n",
    "\n",
    "    def move_to(\n",
    "        tensor: Tensor, other: Tensor, \n",
    "        dtype: Optional[Any] = None, do_dtype: Optional[bool] = True\n",
    "    ) -> Tensor:\n",
    "        '''\n",
    "        Makes sure `tensor` is on the same device as `other`\n",
    "        \n",
    "        Parameters\n",
    "        ----------    \n",
    "        tensor : Tensor\n",
    "            pytorch tensor to change device of\n",
    "            \n",
    "        other : Tensor\n",
    "            pytorch tensor we want `tensor` to be on\n",
    "            \n",
    "        dtype : optional\n",
    "            the data type to make `tensor`. If `None` will infer it\n",
    "            from `other`\n",
    "            \n",
    "        do_dype: bool, default=True\n",
    "            whether or not to just match the device of `other` or also\n",
    "            the dtype\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : Tensor\n",
    "        '''\n",
    "        \n",
    "        if not is_tensor(tensor):\n",
    "            tensor = to_torch(tensor)\n",
    "            \n",
    "        # NOTE: dtype not provided, so we will infer it\n",
    "        if dtype is None:\n",
    "            # NOTE: this little line solves mps float64 issues since \n",
    "            #       infer our tensor types and move them accordingly\n",
    "            other = ensure_mps_dtype(other)\n",
    "            dtype = other.dtype\n",
    "\n",
    "        if do_dtype:\n",
    "            tensor = tensor.to(dtype)\n",
    "\n",
    "        tensor = tensor.to(other.device)\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "except ImportError as err:\n",
    "    identity = lambda x: x\n",
    "    ensure_device = identity\n",
    "    to_cuda = identity\n",
    "    to_mps = identity\n",
    "    to_torch = lambda arr, cuda, mps, device, dtype: arr\n",
    "    to_np = identity\n",
    "    is_mps_available = lambda: False\n",
    "    coerce_mps_dtype = lambda dtype, device, assume_on_mps: dtype\n",
    "    ensure_mps_dtype = identity\n",
    "    move_to = lambda tensor, other, dtype, do_dtype: tensor\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "try:\n",
    "    import torch, pytorch_lightning as pl\n",
    "    def set_seeds(seed: int) -> None:\n",
    "        '''\n",
    "        Calls a bunch of seed functions with `seed`\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int\n",
    "        '''    \n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)    \n",
    "        pl.seed_everything(seed)\n",
    "except ImportError as err:\n",
    "     def set_seeds(seed: int) -> None:\n",
    "         random.seed(seed)\n",
    "         np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f29e9",
   "metadata": {},
   "source": [
    "## Ex\n",
    "> This notebook was generated from [_09_exp.ipynb](/Users/solst/Projects/iza/nbs/_02_utils/_09_exp.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, yaml, datetime, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def config_exp_logger(path):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ----------\n",
    "        path (str): full path to experiment, i.e. \n",
    "            `<path-to-experiments-dir>/<experiment-timestamp>`\n",
    "    Returns:\n",
    "    ----------\n",
    "        logger\n",
    "    '''\n",
    "    basename = os.path.basename(path)\n",
    "    logger = logging.getLogger(basename)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        filename=exp_log_filename(path), \n",
    "        encoding='utf-8',\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s\\t%(levelname)s:%(message)s',\n",
    "        datefmt='%d/%m/%Y %I:%M:%S %p',\n",
    "        filemode='w'\n",
    "    )\n",
    "    logger.info(f'Experiment path created {path}')\n",
    "    return logger\n",
    "\n",
    "def exp_log_filename(path):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ----------\n",
    "        path (str): full path to experiment, i.e. \n",
    "            `<path-to-experiments-dir>/<experiment-timestamp>`\n",
    "    Returns:\n",
    "    ----------\n",
    "        log_file (str): full path to provided experiment's log file\n",
    "    '''\n",
    "    return os.path.join(path, 'log.txt')\n",
    "\n",
    "def exp_param_filename(path):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ----------\n",
    "        path (str): full path to experiment, i.e. \n",
    "            `<path-to-experiments-dir>/<experiment-timestamp>`\n",
    "    Returns:\n",
    "    ----------\n",
    "        param_file (str): full path to provided experiment's parameter file\n",
    "    '''\n",
    "    return os.path.join(path, 'params.yml')\n",
    "\n",
    "def list_exps(path):\n",
    "    '''\n",
    "    Notes:\n",
    "    ----------\n",
    "        - an experiment is defined as a directory containing a `'params.yml'` file.\n",
    "    Arguments:\n",
    "    ----------\n",
    "        path (str): full path to experiments directory, i.e. \n",
    "            `<path-to-experiments-dir>`\n",
    "    Returns:\n",
    "    ----------\n",
    "        experiments (str[]): experiments (subdirectories) in the specified \n",
    "            `path`.\n",
    "    '''\n",
    "    test_fn = lambda el: os.path.isdir(el) and os.path.isfile(exp_param_filename(el))\n",
    "    return list(filter(test_fn, os.listdir(path)))\n",
    "\n",
    "def gen_exp_name(name=None):\n",
    "    '''    \n",
    "    Returns:\n",
    "    ----------\n",
    "        exp_name (str): timestamp to serve as experiment name\n",
    "    '''\n",
    "    if name is None:\n",
    "        now =  datetime.datetime.now()\n",
    "        return now.strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "    return name\n",
    "        \n",
    "def load_exp_params(path):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ----------\n",
    "        path (str): full path to experiment, i.e. \n",
    "            `<path-to-experiments-dir>/<experiment-timestamp>`\n",
    "    Returns:\n",
    "    ----------\n",
    "        params (dict): the loaded parameters\n",
    "    '''\n",
    "    with open(exp_param_filename(path)) as f:\n",
    "        return yaml.safe_load(f)\n",
    "    \n",
    "\n",
    "def save_exp_params(path, params, logger=None):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ----------\n",
    "        path (str): full path to experiment, i.e. \n",
    "            `<path-to-experiments-dir>/<experiment-timestamp>`\n",
    "        params (dict): dictionary of parameters to save\n",
    "        logger (logging.Logger): Defaults to None.\n",
    "    '''\n",
    "    with open(exp_param_filename(path), 'w') as f:\n",
    "        yaml.dump(params, f, default_flow_style=False)\n",
    "    if logger: \n",
    "        logger.info('Experiment parameters saved.')\n",
    "\n",
    "def setup_exp(path, params, name=None):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ----------\n",
    "        path (str): full path to where to create experiments, i.e. \n",
    "            `<path-to-experiments-dir>`\n",
    "        params (dict): dictionary of parameters to save\n",
    "    Returns:\n",
    "    ----------\n",
    "        exp_dir (str): full path to experiment, i.e. \n",
    "            `<path-to-experiments-dir>/<experiment-timestamp>`\n",
    "        logger (logging.Logger)\n",
    "    '''\n",
    "    exp_name = gen_exp_name(name)\n",
    "    exp_dir = os.path.join(path, exp_name)\n",
    "    if not os.path.isdir(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    logger = config_exp_logger(exp_dir)    \n",
    "    save_exp_params(exp_dir, params, logger)\n",
    "    return exp_dir, logger\n",
    "\n",
    "    \n",
    "def is_config_subset(truth, params):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ----------\n",
    "        truth (dict): dictionary of parameters to compare to\n",
    "        params (dict): dictionary of parameters to test\n",
    "    Returns:\n",
    "    ----------\n",
    "        result (bool) whether or not `params` is a subset of `truth`\n",
    "    '''\n",
    "    if not type(truth) == type(params): return False\n",
    "    for key, val in params.items():\n",
    "        if key not in truth: return False\n",
    "        if type(val) is dict:\n",
    "            if not is_config_subset(truth[key], val): \n",
    "                return False\n",
    "        else:            \n",
    "            if not truth[key] == val: return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def find_exps(path, params):\n",
    "    '''\n",
    "    Arguments:\n",
    "    ----------\n",
    "        path (str): full path to where to create experiments, i.e. \n",
    "            `<path-to-experiments-dir>`\n",
    "        params (dict): dictionary of parameters to test\n",
    "    Returns:\n",
    "    ----------\n",
    "        results (str[]) list of experiment names where their parameters are \n",
    "            supersets of the provided `params`\n",
    "    '''\n",
    "    exps = list_exps(path)\n",
    "    results = []\n",
    "    for exp in exps:\n",
    "        exp_name = os.path.join(path, exp)\n",
    "        exp_params = load_exp_params(exp_param_filename(exp_name))\n",
    "        if is_config_subset(exp_params, params):\n",
    "            results.append(exp)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
